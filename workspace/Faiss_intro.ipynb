{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üìÅ1.Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pair_ID\\tsentence_A\\tsentence_B\\trelatedness_score\\tentailment_judgment\\n1\\tA group of kids is playing in '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "\n",
    "text = res.text\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(StringIO(text), sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take all samples from `sentence_A` and build sentence embeddings for each - which we can then store in FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of kids is playing in a yard and an old man is standing in the background',\n",
       " 'A group of children is playing in the house and there is no man standing in the background',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby',\n",
       " 'The kids are playing outdoors near a man with a smile',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data['sentence_A'].tolist()\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)\n",
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **This isn't a particularly large number, so let's pull in a few more similar datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='skip')\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üì¶2. Save as .txt file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and NaN\n",
    "sentences = [\n",
    "    sentence.replace('\\n', '') for sentence in list(set(sentences)) if type(sentence) is str\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üß†3. Sentence Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 16:02:51.719749: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-16 16:02:51.851192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752670971.898252   13018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752670971.911353   13018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752670972.016837   13018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752670972.016853   13018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752670972.016854   13018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752670972.016855   13018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-16 16:02:52.028755: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365342bfc284b588318ed190277c1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47939ccd5ab64a148258f80725f0dcdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7006117496b4f5f9541facdaf9aa778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d16462312c648779a7d4c6d904b74d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00d69dd10394499812bf9d40b5b01be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f680714a28cb48afb598aee72f98a9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9257d75cc53344b2a577ac8e4eaaac07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedb9dbd28a7462da04334f925fb9ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "model = model.to(\"cuda\")  # Move model to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save/load from file in the case of needing to reload the notebook for any reason later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52d929959af402599446349518107fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = model.encode(\"Saher\", batch_size=32, show_progress_bar=True, device=\"cuda\")\n",
    "sen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./sim_sentences/embeddings_X.npy', 'wb') as fp: # Save the embeddings to a file called embeddings_X.npy\n",
    "    np.save(fp, sentence_embeddings[0:256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üìö4. Save Embedding in Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_0.npy | 0 -> 256\n",
      "embeddings_1.npy | 256 -> 512\n",
      "embeddings_2.npy | 512 -> 768\n",
      "embeddings_3.npy | 768 -> 1024\n",
      "embeddings_4.npy | 1024 -> 1280\n",
      "embeddings_5.npy | 1280 -> 1536\n",
      "embeddings_6.npy | 1536 -> 1792\n",
      "embeddings_7.npy | 1792 -> 2048\n",
      "embeddings_8.npy | 2048 -> 2304\n",
      "embeddings_9.npy | 2304 -> 2560\n",
      "embeddings_10.npy | 2560 -> 2816\n",
      "embeddings_11.npy | 2816 -> 3072\n",
      "embeddings_12.npy | 3072 -> 3328\n",
      "embeddings_13.npy | 3328 -> 3584\n",
      "embeddings_14.npy | 3584 -> 3840\n",
      "embeddings_15.npy | 3840 -> 4096\n",
      "embeddings_16.npy | 4096 -> 4352\n",
      "embeddings_17.npy | 4352 -> 4608\n",
      "embeddings_18.npy | 4608 -> 4864\n",
      "embeddings_19.npy | 4864 -> 5120\n",
      "embeddings_20.npy | 5120 -> 5376\n",
      "embeddings_21.npy | 5376 -> 5632\n",
      "embeddings_22.npy | 5632 -> 5888\n",
      "embeddings_23.npy | 5888 -> 6144\n",
      "embeddings_24.npy | 6144 -> 6400\n",
      "embeddings_25.npy | 6400 -> 6656\n",
      "embeddings_26.npy | 6656 -> 6912\n",
      "embeddings_27.npy | 6912 -> 7168\n",
      "embeddings_28.npy | 7168 -> 7424\n",
      "embeddings_29.npy | 7424 -> 7680\n",
      "embeddings_30.npy | 7680 -> 7936\n",
      "embeddings_31.npy | 7936 -> 8192\n",
      "embeddings_32.npy | 8192 -> 8448\n",
      "embeddings_33.npy | 8448 -> 8704\n",
      "embeddings_34.npy | 8704 -> 8960\n",
      "embeddings_35.npy | 8960 -> 9216\n",
      "embeddings_36.npy | 9216 -> 9472\n",
      "embeddings_37.npy | 9472 -> 9728\n",
      "embeddings_38.npy | 9728 -> 9984\n",
      "embeddings_39.npy | 9984 -> 10240\n",
      "embeddings_40.npy | 10240 -> 10496\n",
      "embeddings_41.npy | 10496 -> 10752\n",
      "embeddings_42.npy | 10752 -> 11008\n",
      "embeddings_43.npy | 11008 -> 11264\n",
      "embeddings_44.npy | 11264 -> 11520\n",
      "embeddings_45.npy | 11520 -> 11776\n",
      "embeddings_46.npy | 11776 -> 12032\n",
      "embeddings_47.npy | 12032 -> 12288\n",
      "embeddings_48.npy | 12288 -> 12544\n",
      "embeddings_49.npy | 12544 -> 12800\n",
      "embeddings_50.npy | 12800 -> 13056\n",
      "embeddings_51.npy | 13056 -> 13312\n",
      "embeddings_52.npy | 13312 -> 13568\n",
      "embeddings_53.npy | 13568 -> 13824\n",
      "embeddings_54.npy | 13824 -> 14080\n",
      "embeddings_55.npy | 14080 -> 14336\n",
      "embeddings_56.npy | 14336 -> 14505\n"
     ]
    }
   ],
   "source": [
    "# saving data\n",
    "split = 256\n",
    "file_count = 0\n",
    "for i in range(0, sentence_embeddings.shape[0], split):\n",
    "    end = i + split\n",
    "    if end > sentence_embeddings.shape[0] + 1:\n",
    "        end = sentence_embeddings.shape[0] + 1\n",
    "    file_count = '0' + str(file_count) if file_count < 0 else str(file_count)\n",
    "    with open(f'./sim_sentences/embeddings_{file_count}.npy', 'wb') as fp:\n",
    "        np.save(fp, sentence_embeddings[i:end, :])\n",
    "    print(f\"embeddings_{file_count}.npy | {i} -> {end}\")\n",
    "    file_count = int(file_count) + 1\n",
    "\n",
    "# this code will save the embeddings in chunks of 256 to avoid memory issues \n",
    "# example: if you have 1000 embeddings, it will save 4 files: embeddings_00.npy, embeddings_01.npy, embeddings_02.npy, embeddings_03.npy\n",
    "# each file will contain 256 embeddings except the last one which will contain the remaining embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üìä5. FAAIS implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IndexFlatL2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We initialize the flat L2 distance index `IndexFlatL2`, all we need is the specify the vector dimensionality - which in this case is `d == 768` (to align with the sentence-BERT model output embeddings of size `768`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we will use indexes that require us to `train` them on our data before being used (if we are grouping or transforming the data in any way). `IndexFlatL2` however, is a simple operation and only requires that we calculate distances between vectors when we introduce our query vector `xq` during search. So, in this case, no training is required - which we can confirm by checking the `is_trained` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then search given a query `xq` and number of nearest neigbors to return `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "xq = model.encode([\"something that is related to computer scince and software engineering\"], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14283  9805   638 11555  9098  8724 13055   181   900  3075   239  5093\n",
      "   4152  5693   462 11370  3221  5681  5387 14133]]\n",
      "CPU times: user 2.57 ms, sys: 0 ns, total: 2.57 ms\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)  # k-nearest neigbors of the query vector | nprobe == 1: 6495 26392 61709 49932 | nprobe == 10: 36245  6495 57489  8705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're returning indices which returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14283: create code or computer programs',\n",
       " '9805: (computer science) a program designed for general support of the processes of a computer.',\n",
       " '638: a computer program that performs system support',\n",
       " '11555: the primary information-processing component of a computer, of a microprocessor chip',\n",
       " '9098: create code, write a computer program.',\n",
       " '8724: (computer science) the part of a computer (a microprocessor chip) that does most of the data processing.',\n",
       " '13055: write a computer program.',\n",
       " '181: Write a computer programme.',\n",
       " '900: an image that is generated by a computer.',\n",
       " '3075: obtain or retrieve from a storage device; as of information on a computer.',\n",
       " '239: Obtain from a storage device, as of information on a computer.',\n",
       " '5093: the ability of computers to exchange digital information between them and make use of it',\n",
       " '4152: a computer server',\n",
       " '5693: (computer science) matter that is held in a computer and is typed or printed on paper.',\n",
       " '462: (computer science) the ability to exchange and use information (usually in a large heterogeneous network made up of several local area networks).',\n",
       " '11370: a computer-generated visual image',\n",
       " '3221: (computer science) a computer that provides client stations with access to files and printers as shared resources to a computer network.',\n",
       " '5681: printed version of electronic data from a computer',\n",
       " '5387: (computer science) the occurence of an incorrect result produced by a computer.',\n",
       " '14133: (computer science) the occurrence of an incorrect result produced by a computer.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(computer science) matter that is held in a computer and is typed or printed on paper.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[5693]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we have some good matches, everything returned includes people running with a football, or on the context of a football match. Now, if we'd rather extract the numerical vectors from FAISS, we can do that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.zeros((k, d))\n",
    "for i, val in enumerate(I[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 768)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09391017, -0.09907819,  1.24320161,  0.45920768,  0.27596977,\n",
       "       -0.21246122,  0.10113402,  0.8577866 ,  0.21929623, -0.0233299 ,\n",
       "       -0.22599718,  0.30393201,  0.44359925,  0.67798698, -0.68578678,\n",
       "       -0.27133012, -0.72963232, -0.63668185,  0.04318038, -0.072131  ,\n",
       "       -0.55964434, -0.45221475,  0.06749705, -0.49995908,  0.01495562,\n",
       "        0.11168762, -0.00734872, -0.41647235, -0.99219048, -0.09018803,\n",
       "       -0.78419036, -0.45411903,  1.25811863, -0.86799634,  0.39596888,\n",
       "        0.69694793,  0.13326345,  0.74794763,  0.12864989, -0.21554826,\n",
       "       -0.36342981, -0.7541362 ,  0.60532933,  0.90233713, -0.42201591,\n",
       "       -0.60834563, -0.75992382,  0.51503366, -0.02454788, -0.34889325,\n",
       "       -1.0836519 ,  0.90496981,  0.53311056,  0.65428096, -0.02545676,\n",
       "        0.73733759,  1.13248825, -1.69231999,  0.07980368,  0.67105812,\n",
       "        0.38921386,  0.01704967,  0.33874604,  0.420077  ,  0.06318744,\n",
       "        0.02256099,  0.40185109, -0.36326689, -1.47796416, -0.82788581,\n",
       "        0.36047569, -0.50276726, -0.83132738,  0.1682279 , -0.84269708,\n",
       "       -0.11027478,  0.1404887 ,  0.13090518,  1.18275774,  0.45817995,\n",
       "        0.36386558,  0.6654337 ,  1.14420295,  0.36719316,  0.95780814,\n",
       "       -0.6189909 ,  0.32103744,  0.23810646, -1.18789887,  0.04139939,\n",
       "       -0.03703131,  0.51401961, -0.23016015,  0.17366652,  0.38299116,\n",
       "       -0.58827055, -0.42128998,  0.18224053, -0.47458586,  0.22564045])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IndexIVFFlat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 50 # number of Voronoi cells (clusters)\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've added a new parameter `nlist`. We use `nlist` to define how many partitions we'd like our index to have. \n",
    "\n",
    "When we built the previous, `IndexFlatL2`-only index, we noted that no training was required as no grouping/transformation was required to build that index. Now that we've added partitioning using `IndexIVFFlat`, this is no longer the case. Let's take a look at the `is_trained` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.train(sentence_embeddings)\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search again using the same indexed sentence embeddings and the same query `xq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14283   638  3075   239  5093  4152  1504  5549 13285  5211  9494  5422\n",
      "   2773  2663 10276  1478  5445  7346  1019  5919]]\n",
      "CPU times: user 952 ¬µs, sys: 0 ns, total: 952 ¬µs\n",
      "Wall time: 730 ¬µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase the number of nearby cells to search too with `nprobe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14283  9805   638 11555  9098  8724   181  3075   239  5093  4152   462\n",
      "   3221  5681  7155  9872 10157  6721  9951  1504]]\n",
      "CPU times: user 896 ¬µs, sys: 0 ns, total: 896 ¬µs\n",
      "Wall time: 486 ¬µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of `nprobe` will improve the accuracy of our search, but cost time. Our earlier `IndexFlatL2`-only search was *exhaustive* (it compared every single vector) and so it identified the closest matches with a perfect accuracy. The smaller our `nprobe` value, the smaller scope that we search. We received perfect results (that matched our previous `IndexFlatL2`-only results - `7460`, `10940`, `3781`, `5747`), however, if we found that we were not getting closely matching results, we could simply bump `nprobe` up further - improving accuracy, but increasing time-taken too.\n",
    "\n",
    "It's worth noting that the time taken can change with each run too, if we rerun the above block, we usually get a different time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14283  9805   638 11555  9098  8724 13055   181   900  3075   239  5093\n",
      "   4152  5693   462 11370  3221  5681  9063  5518]]\n",
      "CPU times: user 826 ¬µs, sys: 297 ¬µs, total: 1.12 ms\n",
      "Wall time: 584 ¬µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For IVF (and IMI) indexes, before attempting to use the `reconstruct` method, we need to call the `make_direct_map` method - otherwise we will return a `RunetimeError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.make_direct_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09391017, -0.09907819,  1.2432016 ,  0.45920768,  0.27596977,\n",
       "       -0.21246122,  0.10113402,  0.8577866 ,  0.21929623, -0.0233299 ,\n",
       "       -0.22599718,  0.303932  ,  0.44359925,  0.677987  , -0.6857868 ,\n",
       "       -0.27133012, -0.7296323 , -0.63668185,  0.04318038, -0.072131  ,\n",
       "       -0.55964434, -0.45221475,  0.06749705, -0.49995908,  0.01495562,\n",
       "        0.11168762, -0.00734872, -0.41647235, -0.9921905 , -0.09018803,\n",
       "       -0.78419036, -0.45411903,  1.2581186 , -0.86799634,  0.39596888,\n",
       "        0.69694793,  0.13326345,  0.74794763,  0.12864989, -0.21554826,\n",
       "       -0.3634298 , -0.7541362 ,  0.60532933,  0.90233713, -0.4220159 ,\n",
       "       -0.6083456 , -0.7599238 ,  0.51503366, -0.02454788, -0.34889325,\n",
       "       -1.0836519 ,  0.9049698 ,  0.53311056,  0.65428096, -0.02545676,\n",
       "        0.7373376 ,  1.1324883 , -1.69232   ,  0.07980368,  0.6710581 ,\n",
       "        0.38921386,  0.01704967,  0.33874604,  0.420077  ,  0.06318744,\n",
       "        0.02256099,  0.4018511 , -0.3632669 , -1.4779642 , -0.8278858 ,\n",
       "        0.3604757 , -0.50276726, -0.8313274 ,  0.1682279 , -0.8426971 ,\n",
       "       -0.11027478,  0.1404887 ,  0.13090518,  1.1827577 ,  0.45817995,\n",
       "        0.36386558,  0.6654337 ,  1.144203  ,  0.36719316,  0.95780814,\n",
       "       -0.6189909 ,  0.32103744,  0.23810646, -1.1878989 ,  0.04139939,\n",
       "       -0.03703131,  0.5140196 , -0.23016015,  0.17366652,  0.38299116,\n",
       "       -0.58827055, -0.42128998,  0.18224053, -0.47458586,  0.22564045],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.reconstruct(14283)[:100] # reconstruct the 100 nearest neighbors for the vector at index 14283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8  # number of chunks in compressed vectors (sub-vectors)\n",
    "bits = 8 # number of bits per chunk\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare it to our previous index *without* PQ, and an `nprobe` value of `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.nprobe = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  239   638  3075  4152  5093 14283   181  9098  5681  9805   900  5518\n",
      "  11370  3221  8724 11555  9063 10157  3948   462]]\n",
      "CPU times: user 533 ¬µs, sys: 167 ¬µs, total: 700 ¬µs\n",
      "Wall time: 417 ¬µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through adding PQ we've reduced our search time from ~7.5ms to ~5ms, a small difference on a dataset of this size, but when scaled to larger datasets this can make a huge difference.\n",
    "\n",
    "Now, we should also notice the slightly different results being returned. Beforehand with our exhaustive L2 search we were returning `7460`, `10940`, `3781`, and `5747`. Now, we see a slightly different order to our results - and two different vectors, `5013` and `5370`.\n",
    "\n",
    "Each of our speed optimization operations, `IVF` and `PQ`, come at the cost of accuracy. Now, if we print out these results we will nonetheless find that each item is still a relevant match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['239: Obtain from a storage device, as of information on a computer.',\n",
       " '638: a computer program that performs system support',\n",
       " '3075: obtain or retrieve from a storage device; as of information on a computer.',\n",
       " '4152: a computer server',\n",
       " '5093: the ability of computers to exchange digital information between them and make use of it',\n",
       " '14283: create code or computer programs',\n",
       " '181: Write a computer programme.',\n",
       " '9098: create code, write a computer program.',\n",
       " '5681: printed version of electronic data from a computer',\n",
       " '9805: (computer science) a program designed for general support of the processes of a computer.',\n",
       " '900: an image that is generated by a computer.',\n",
       " '5518: an electronic memory device.',\n",
       " '11370: a computer-generated visual image',\n",
       " '3221: (computer science) a computer that provides client stations with access to files and printers as shared resources to a computer network.',\n",
       " '8724: (computer science) the part of a computer (a microprocessor chip) that does most of the data processing.',\n",
       " '11555: the primary information-processing component of a computer, of a microprocessor chip',\n",
       " '9063: a set sequence of steps, part of larger computer program.',\n",
       " '10157: COMPUTERS: obtain data/images from magnetic tapes or with a beam of light',\n",
       " '3948: cause (a computer) to execute a single command.',\n",
       " '462: (computer science) the ability to exchange and use information (usually in a large heterogeneous network made up of several local area networks).']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **So although we might not get the *perfect* result, we still get close - we get a significant speed boost**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
